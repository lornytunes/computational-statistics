{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.stattools as smtsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('lib')\n",
    "\n",
    "import compstats\n",
    "import hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.pylabtools import figsize\n",
    "sns.set_theme()\n",
    "figsize(11, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from \"Price of Weed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_csv('data/mj-clean.csv', parse_dates=[5])\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes a DataFrame of transactions and compute daily averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_day(transactions: pd.DataFrame, func=np.mean) -> pd.DataFrame:\n",
    "    \"\"\"Groups transactions by day and compute the daily mean ppg.\n",
    "\n",
    "    transactions: DataFrame of transactions\n",
    "\n",
    "    returns: DataFrame of daily prices\n",
    "    \"\"\"\n",
    "    grouped = transactions[['date', 'ppg']].groupby('date')\n",
    "    daily = grouped.aggregate(func)\n",
    "\n",
    "    daily['date'] = daily.index\n",
    "    start = daily.date[0]\n",
    "    one_year = np.timedelta64(1, 'Y')\n",
    "    # dt / 1 year\n",
    "    daily['years'] = (daily.date - start) / one_year\n",
    "\n",
    "    return daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_day(transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function returns a map from quality name to a DataFrame of daily averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def group_by_quality_and_day(transactions: pd.DataFrame) -> OrderedDict[str, pd.DataFrame]:\n",
    "    \"\"\"Divides transactions by quality and computes mean daily price.\n",
    "\n",
    "    transaction: DataFrame of transactions\n",
    "    \n",
    "    returns: map from quality to time series of ppg\n",
    "    \"\"\"\n",
    "    groups = transactions.groupby('quality')\n",
    "    dailies = OrderedDict()\n",
    "    for name, group in groups:\n",
    "        dailies[name] = group_by_day(group)        \n",
    "\n",
    "    return dailies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_quality_and_day(transactions).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the quality categories in order\n",
    "transactions['quality'] = pd.Categorical(\n",
    "    transactions.quality.values,\n",
    "    categories=['high', 'medium', 'low'],\n",
    "    ordered=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, _ in transactions.groupby('quality'):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_quality_and_day(transactions).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dailies` is the map from quality name to DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailies = group_by_quality_and_day(transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plots the daily average price for each quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _ = plt.subplots(nrows=len(dailies), ncols=1, figsize=(11, 13))\n",
    "for i, (name, daily) in enumerate(dailies.items()):\n",
    "    # n rows and 1 column\n",
    "    plt.subplot(len(dailies), 1, i+1)\n",
    "    plt.scatter(\n",
    "        daily.index,\n",
    "        daily.ppg,\n",
    "        alpha=0.2,\n",
    "        label=name\n",
    "    )\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylim([0, 20])\n",
    "    if i == 0:\n",
    "        plt.title('Price per gram ($)')\n",
    "    if i == len(dailies) - 1:\n",
    "        plt.xticks(rotation=30)\n",
    "    else:\n",
    "        plt.xticks([])\n",
    "fig.suptitle('Time series of daily price per gram for high, medium, and low quality cannabis.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `statsmodels` to run a linear model of price as a function of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(results, show_std=True):\n",
    "    \"\"\"Prints the most important parts of linear regression results:\n",
    "\n",
    "    results: RegressionResults object\n",
    "    \"\"\"\n",
    "    for name, param in results.params.items():\n",
    "        pvalue = results.pvalues[name]\n",
    "        print(f'{name:26}: {param:0.4f}: {pvalue:0.4f}')\n",
    "    try:\n",
    "        print(f'R^2      : {results.rsquared:0.4f}')\n",
    "        if show_std:\n",
    "            print(f'Std(ys)  : {results.model.endog.std():0.4f}')\n",
    "            print(f'Std(res) : {results.resid.std():0.4f}')\n",
    "    except AttributeError:\n",
    "        print(f'R^2      : {results.prsquared:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the results look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, daily in dailies.items():\n",
    "    results = smf.ols('ppg ~ years', data=daily).fit()\n",
    "    print('\\n{}'.format(name))\n",
    "    summarize_results(results, show_std=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated slopes indicate that the price of high quality cannabis dropped by about 71 cents per year during the observed interval; for medium quality it increased by 28 cents per year, and for low quality it increased by 57 cents per year. These estimates are all statistically significant with very small p-values.\n",
    "\n",
    "The $R^2$ value for high quality cannabis is 0.44, which means that time as an explanatory variable accounts for 44% of the observed variability in price. For the other qualities, the change in price is smaller, and variability in prices is higher, so the values of $R^2$ are smaller (but still statistically significant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_model(daily: pd.DataFrame):\n",
    "    model = smf.ols('ppg ~ years', data=daily)\n",
    "    results = model.fit()\n",
    "    return model, results\n",
    "\n",
    "def fit_linear_model(daily: pd.DataFrame):\n",
    "    return smf.ols('ppg ~ years', data=daily).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the fitted model with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fitted_values(model, results, label=''):\n",
    "    \"\"\"Plots original data and fitted values.\n",
    "\n",
    "    model: StatsModel model object\n",
    "    results: StatsModel results object\n",
    "    \"\"\"\n",
    "    years = model.exog[:,1]\n",
    "    values = model.endog\n",
    "    plt.scatter(years, values, s=15, label=label)\n",
    "    plt.plot(years, results.fittedvalues, label='model', color='#ff7f00')\n",
    "    plt.xlabel('Years')\n",
    "    plt.xlim([-0.1, 3.8])\n",
    "    plt.ylabel('Price per gram ($)');\n",
    "    plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(11, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series of daily price per gram for high quality cannabis, and a linear least squares fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function plots the original data and the fitted curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_linear_model(daily, name):\n",
    "    \"\"\"Plots a linear fit to a sequence of prices, and the residuals.\n",
    "    \n",
    "    daily: DataFrame of daily prices\n",
    "    name: string\n",
    "    \"\"\"\n",
    "    model, results = run_linear_model(daily)\n",
    "    plot_fitted_values(model, results, label=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are results for the high quality category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'high'\n",
    "daily = dailies[name]\n",
    "plot_linear_model(daily, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving averages\n",
    "\n",
    "As a simple example, I'll show the rolling average of the numbers from 1 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.arange(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a \"window\" of size 3, we get the average of the previous 3 elements, or nan when there are fewer than 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But Series now provides `rolling`\n",
    "series = pd.Series(array)\n",
    "series.rolling(3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function plots the rolling mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rolling_mean(daily, name):\n",
    "    \"\"\"Plots rolling mean.\n",
    "\n",
    "    daily: DataFrame of daily prices\n",
    "    \"\"\"\n",
    "    dates = pd.date_range(daily.index.min(), daily.index.max())\n",
    "    reindexed = daily.reindex(dates)\n",
    "\n",
    "    plt.scatter(reindexed.index, reindexed.ppg, s=15, alpha=0.2, label=name)\n",
    "    # roll_mean = pd.rolling_mean(reindexed.ppg, 30)\n",
    "    roll_mean = reindexed.ppg.rolling(30).mean()\n",
    "    plt.plot(roll_mean, label='rolling mean', color='#ff7f00')\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.ylabel('price per gram ($)')\n",
    "    plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what it looks like for the high quality category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rolling_mean(dailies['high'], 'High')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exponentially-weighted moving average gives more weight to more recent points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ewma(daily, name):\n",
    "    \"\"\"Plots rolling mean.\n",
    "\n",
    "    daily: DataFrame of daily prices\n",
    "    \"\"\"\n",
    "    dates = pd.date_range(daily.index.min(), daily.index.max())\n",
    "    reindexed = daily.reindex(dates)\n",
    "\n",
    "    plt.scatter(reindexed.index, reindexed.ppg, s=15, alpha=0.2, label=name)\n",
    "    roll_mean = reindexed.ppg.ewm(30).mean()\n",
    "    plt.plot(roll_mean, label='EWMA', color='#ff7f00')\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.xlabel('price per gram ($)')\n",
    "    plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ewma(dailies['high'], 'High')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use resampling to generate missing values with the right amount of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(daily, span=30):\n",
    "    \"\"\"Fills missing values with an exponentially weighted moving average.\n",
    "\n",
    "    Resulting DataFrame has new columns 'ewma' and 'resid'.\n",
    "\n",
    "    daily: DataFrame of daily prices\n",
    "    span: window size (sort of) passed to ewma\n",
    "\n",
    "    returns: new DataFrame of daily prices\n",
    "    \"\"\"\n",
    "    \n",
    "    # fill in the gaps in the dates\n",
    "    dates = pd.date_range(daily.index.min(), daily.index.max())\n",
    "    reindexed = daily.reindex(dates)\n",
    "    # fill the missing values with the moving average\n",
    "    ewma = reindexed.ppg.ewm(span=span).mean()\n",
    "    # residuals values not including days when ppg is nan\n",
    "    resid = (reindexed.ppg - ewma).dropna()\n",
    "    # sum of the moving average and a random sample of the residuals\n",
    "    fake_data = ewma + compstats.resample_n(resid, len(reindexed))\n",
    "    # finally replace nan with values from fake_data\n",
    "    reindexed.ppg.fillna(fake_data, inplace=True)\n",
    "    # store our moving average and noise components\n",
    "    reindexed['ewma'] = ewma\n",
    "    reindexed['resid'] = reindexed.ppg - ewma\n",
    "    return reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filled(daily, name):\n",
    "    \"\"\"Plots the EWMA and filled data.\n",
    "\n",
    "    daily: DataFrame of daily prices\n",
    "    \"\"\"\n",
    "    filled = fill_missing(daily, span=30)\n",
    "    plt.scatter(filled.index, filled.ppg, s=15, alpha=0.2, label=name)\n",
    "    plt.plot(filled.ewma, label='EWMA', color='#ff7f00')\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.xlabel('price per gram ($)')\n",
    "    plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the EWMA model looks like with missing values filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_filled(dailies['high'], 'High')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial correlation\n",
    "\n",
    "As prices vary from day to day, you might expect to see patterns. If the price is high on Monday, you might expect it to be high for a few more days; and if it’s low, you might expect it to stay low.\n",
    "\n",
    "A pattern like this is called serial correlation, because each value is correlated with the next one in the series. To compute serial correlation, we can shift the time series by an interval called a lag, and then compute the correlation of the shifted series with the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series(array)\n",
    "series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 1\n",
    "# everything but the first item\n",
    "xs = series[lag:]\n",
    "xs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift to the right. each element get the value of the element before it.\n",
    "ys = series.shift(lag)\n",
    "ys.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the nan at the beginning\n",
    "ys = ys[lag:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so `ys` lags behind `xs` by 1. Finally compute the correlation between `xs` and `ys`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compstats.corr(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xs, ys, lag, series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function computes serial correlation with the given lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serial_corr(series, lag=1):\n",
    "    # 0-9 -> 1-9\n",
    "    xs = series[lag:]\n",
    "    # 0-8\n",
    "    ys = series.shift(lag)[lag:]\n",
    "    # (1,0),(2,1),(3,2),(4,3) etc\n",
    "    return compstats.corr(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before computing correlations, we'll fill missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_dailies = {}\n",
    "for name, daily in dailies.items():\n",
    "    filled_dailies[name] = fill_missing(daily, span=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the serial correlations for raw price data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, filled in filled_dailies.items():            \n",
    "    corr = serial_corr(filled.ppg, lag=1)\n",
    "    print(f'{name:12}: {corr:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not surprising that there are correlations between consecutive days, because there are obvious trends in the data.\n",
    "\n",
    "It is more interesting to see if the correlation persists if you subtract away the trend. For example, we can compute the residual of the EWMA and then compute its serial correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, daily in filled_dailies.items():\n",
    "    print(f'{name:12}: {serial_corr(daily.resid, 1):0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if the correlations between consecutive days are weak, there might be correlations across intervals of one week, one month, or one year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in [1, 7, 30, 365]:\n",
    "    print(f'Lag {lag}\\t')\n",
    "    for name, filled in filled_dailies.items():            \n",
    "        corr = serial_corr(filled.resid, lag)\n",
    "        print(f'{name:12}: {corr:0.3f}\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strongest correlation is a weekly cycle in the medium quality category.\n",
    "\n",
    "## Autocorrelation\n",
    "\n",
    "The autocorrelation function is the serial correlation computed for all lags.\n",
    "\n",
    "We can use it to replicate the results from the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled = filled_dailies['high']\n",
    "acf = smtsa.acf(filled.resid, nlags=365, adjusted=True, fft=False)\n",
    "print('%0.2g, %.2g, %0.2g, %0.2g, %0.2g' % \n",
    "      (acf[0], acf[1], acf[7], acf[30], acf[365]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of how much autocorrelation we should expect by chance, we can resample the data (which eliminates any actual autocorrelation) and compute the ACF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_autocorrelation(daily, iters=1001, nlags=40):\n",
    "    \"\"\"Resample residuals, compute autocorrelation, and plot percentiles.\n",
    "\n",
    "    daily: DataFrame\n",
    "    iters: number of simulations to run\n",
    "    nlags: maximum lags to compute autocorrelation\n",
    "    \"\"\"\n",
    "    # run simulations\n",
    "    t = []\n",
    "    for _ in range(iters):\n",
    "        filled = fill_missing(daily, span=30)\n",
    "        resid = compstats.resample(filled.resid)\n",
    "        acf = smtsa.acf(resid, nlags=nlags, adjusted=False, fft=False)[1:]\n",
    "        t.append(np.abs(acf))\n",
    "    high = np.percentile(np.array(t), 97.5, axis=0)\n",
    "    low = -high\n",
    "    lags = range(1, nlags+1)\n",
    "    plt.fill_between(lags, low, high, alpha=0.2, color='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = dailies['high']\n",
    "simulate_autocorrelation(daily)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function plots the actual autocorrelation for lags up to 40 days.\n",
    "\n",
    "The flag `add_weekly` indicates whether we should add a simulated weekly cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what the autocorrelation function looks like when there is a seasonal component, I generated simulated data by adding a weekly cycle. Assuming that demand for cannabis is higher on weekends, we might expect the price to be higher. To simulate this effect, I select dates that fall on Friday or Saturday and add a random amount to the price, chosen from a uniform distribution from \\\\$0 to \\\\$2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weekly_seasonality(daily):\n",
    "    \"\"\"Adds a weekly pattern.\n",
    "\n",
    "    daily: DataFrame of daily prices\n",
    "\n",
    "    returns: new DataFrame of daily prices\n",
    "    \"\"\"\n",
    "    fri_or_sat = (daily.index.dayofweek==4) | (daily.index.dayofweek==5)\n",
    "    weekly = daily.ppg.values.copy()\n",
    "    weekly[fri_or_sat] += np.random.uniform(0, 2, fri_or_sat.sum())\n",
    "    fake = daily.copy()\n",
    "    fake.ppg = weekly\n",
    "    return fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_weekly_seasonality(dailies['high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we improve on this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_autocorrelation(dailies, nlags=40, add_weekly=False):\n",
    "    \"\"\"Plots autocorrelation functions.\n",
    "\n",
    "    dailies: map from category name to DataFrame of daily prices\n",
    "    nlags: number of lags to compute\n",
    "    add_weekly: boolean, whether to add a simulated weekly pattern\n",
    "    \"\"\"\n",
    "    simulate_autocorrelation(dailies['high'])\n",
    "    for i, (name, daily) in enumerate(dailies.items()):\n",
    "        if add_weekly:\n",
    "            daily = add_weekly_seasonality(daily)\n",
    "\n",
    "        filled = fill_missing(daily, span=30)\n",
    "        acf = smtsa.acf(filled.resid, nlags=nlags, adjusted=True, fft=False)\n",
    "        lags = np.arange(len(acf))\n",
    "        plt.plot(lags[1:], acf[1:], label=name)\n",
    "    plt.xlim([0, 41])\n",
    "    plt.ylim([-0.2, 0.2])\n",
    "    plt.xlabel('lag (day)')\n",
    "    plt.ylabel('correlation')\n",
    "    plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show what a strong weekly cycle would look like, we have the option of adding a price increase of 1-2 dollars on Friday and Saturdays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the real ACFs look like.  The gray regions indicate the levels we expect by chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_autocorrelation(dailies, add_weekly=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autocorrelation functions for the three quality categories, with nlags=40. The gray region shows the normal variability we would expect if there is no actual autocorrelation; anything that falls outside this range is statistically significant, with a p-value less than 5%. Since the false positive rate is 5%, and we are computing 120 correlations (40 lags for each of 3 times series), we expect to see about 6 points outside this region. In fact, there are 7. We conclude that there are no autocorrelations in these series that could not be explained by chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what it would look like if there were a weekly cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_autocorrelation(dailies, add_weekly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "The simplest way to generate predictions is to use `statsmodels` to fit a model to the data, then use the `predict` method from the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simple_prediction(results, years):\n",
    "    \"\"\"Generates a simple prediction.\n",
    "\n",
    "    results: results object\n",
    "    years: sequence of times (in years) to make predictions for\n",
    "\n",
    "    returns: sequence of predicted values\n",
    "    \"\"\"\n",
    "    n = len(years)\n",
    "    inter = np.ones(n)\n",
    "    d = dict(Intercept=inter, years=years, years2=years**2)\n",
    "    predict_df = pd.DataFrame(d)\n",
    "    predict = results.predict(predict_df)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fit_linear_model(dailies['high'])\n",
    "# five years ahead\n",
    "years = np.linspace(0, 5, 101)\n",
    "generate_simple_prediction(results, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simple_prediction(daily, results, years, name):\n",
    "    predict = generate_simple_prediction(results, years)\n",
    "\n",
    "    plt.scatter(daily.years, daily.ppg, alpha=0.2, label=name)\n",
    "    plt.plot(years, predict, color='#ff7f00', label='prediction')\n",
    "    plt.xlim([years[0]-0.1, years[-1]+0.1])\n",
    "    plt.xlabel('Years')\n",
    "    plt.ylabel('Price per gram ($)')\n",
    "    plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the prediction looks like for the high quality category, using the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fit_linear_model(dailies['high'])\n",
    "# five years ahead\n",
    "years = np.linspace(0, 5, 101)\n",
    "plot_simple_prediction(dailies['high'], results, years, 'High')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we generate predictions, we want to quatify the uncertainty in the prediction.  We can do that by resampling.  The following function fits a model to the data, computes residuals, then resamples from the residuals to general fake datasets.  It fits the same model to each fake dataset and returns a list of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_results(daily, iters=101, func=fit_linear_model):\n",
    "    \"\"\"Run simulations based on resampling residuals.\n",
    "\n",
    "    daily: DataFrame of daily prices\n",
    "    iters: number of simulations\n",
    "    func: function that fits a model to the data\n",
    "\n",
    "    returns: list of result objects\n",
    "    \"\"\"\n",
    "    results = func(daily)\n",
    "    fake = daily.copy()\n",
    "    \n",
    "    result_seq = []\n",
    "    for _ in range(iters):\n",
    "        fake.ppg = results.fittedvalues + compstats.resample(results.resid)\n",
    "        fake_results = func(fake)\n",
    "        result_seq.append(fake_results)\n",
    "\n",
    "    return result_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate predictions, we take the list of results fitted to resampled data.  For each model, we use the `predict` method to generate predictions, and return a sequence of predictions.\n",
    "\n",
    "If `add_resid` is true, we add resampled residuals to the predicted values, which generates predictions that include predictive uncertainty (due to random noise) as well as modeling uncertainty (due to random sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(result_seq, years, add_resid=False):\n",
    "    \"\"\"Generates an array of predicted values from a list of model results.\n",
    "\n",
    "    When add_resid is False, predictions represent sampling error only.\n",
    "\n",
    "    When add_resid is True, they also include residual error (which is\n",
    "    more relevant to prediction).\n",
    "    \n",
    "    result_seq: list of model results\n",
    "    years: sequence of times (in years) to make predictions for\n",
    "    add_resid: boolean, whether to add in resampled residuals\n",
    "\n",
    "    returns: sequence of predictions\n",
    "    \"\"\"\n",
    "    n = len(years)\n",
    "    d = dict(Intercept=np.ones(n), years=years, years2=years**2)\n",
    "    predict_df = pd.DataFrame(d)\n",
    "    \n",
    "    predict_seq = []\n",
    "    for fake_results in result_seq:\n",
    "        predict = fake_results.predict(predict_df)\n",
    "        if add_resid:\n",
    "            predict += compstats.resample_n(fake_results.resid, n)\n",
    "        predict_seq.append(predict)\n",
    "\n",
    "    return np.array(predict_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize predictions, I show a darker region that quantifies modeling uncertainty and a lighter region that quantifies predictive uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.linspace(0, 5, 101)\n",
    "result_seq = simulate_results(daily, iters=101)\n",
    "predict_seq = generate_predictions(result_seq, years, add_resid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = 90\n",
    "p = (100 - percent) / 2\n",
    "percents = p, 100-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low, high = np.percentile(predict_seq, percents, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    daily.years,\n",
    "    daily.ppg\n",
    ");\n",
    "plt.fill_between(\n",
    "    years,\n",
    "    low,\n",
    "    high,\n",
    "    alpha=0.3,\n",
    "    color='gray'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(daily, years, iters=101, percent=90, func=fit_linear_model):\n",
    "    \"\"\"Plots predictions.\n",
    "\n",
    "    daily: DataFrame of daily prices\n",
    "    years: sequence of times (in years) to make predictions for\n",
    "    iters: number of simulations\n",
    "    percent: what percentile range to show\n",
    "    func: function that fits a model to the data\n",
    "    \"\"\"\n",
    "    result_seq = simulate_results(daily, iters=iters, func=func)\n",
    "    p = (100 - percent) / 2\n",
    "    percents = p, 100-p\n",
    "\n",
    "    predict_seq = generate_predictions(result_seq, years, add_resid=True)\n",
    "    low, high = np.percentile(predict_seq, percents, axis=0)\n",
    "    plt.fill_between(years, low, high, alpha=0.3, color='gray')\n",
    "\n",
    "    predict_seq = generate_predictions(result_seq, years, add_resid=False)\n",
    "    low, high = np.percentile(predict_seq, percents, axis=0)\n",
    "    plt.fill_between(years, low, high, alpha=0.5, color='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results for the high quality category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.linspace(0, 5, 101)\n",
    "plt.scatter(daily.years, daily.ppg, alpha=0.1, label='High')\n",
    "plot_predictions(daily, years)\n",
    "plt.xlim([years[0]-0.1, years[-1]+0.1])\n",
    "plt.xlabel('Years');\n",
    "plt.ylabel('Price per gram ($)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there is one more source of uncertainty: how much past data should we use to build the model?\n",
    "\n",
    "The following function generates a sequence of models based on different amounts of past data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_intervals(daily, iters=101, func=fit_linear_model):\n",
    "    \"\"\"Run simulations based on different subsets of the data.\n",
    "\n",
    "    daily: DataFrame of daily prices\n",
    "    iters: number of simulations\n",
    "    func: function that fits a model to the data\n",
    "\n",
    "    returns: list of result objects\n",
    "    \"\"\"\n",
    "    result_seq = []\n",
    "    starts = np.linspace(0, len(daily), iters).astype(int)\n",
    "\n",
    "    for start in starts[:-2]:\n",
    "        subset = daily[start:]\n",
    "        results = func(subset)\n",
    "        fake = subset.copy()\n",
    "\n",
    "        for _ in range(iters):\n",
    "            fake.ppg = (\n",
    "                results.fittedvalues + compstats.resample(results.resid)\n",
    "            )\n",
    "            fake_results = func(fake)\n",
    "            result_seq.append(fake_results)\n",
    "\n",
    "    return result_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this function plots the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_intervals(daily, years, iters=101, percent=90, func=fit_linear_model):\n",
    "    \"\"\"Plots predictions based on different intervals.\n",
    "\n",
    "    daily: DataFrame of daily prices\n",
    "    years: sequence of times (in years) to make predictions for\n",
    "    iters: number of simulations\n",
    "    percent: what percentile range to show\n",
    "    func: function that fits a model to the data\n",
    "    \"\"\"\n",
    "    result_seq = simulate_intervals(daily, iters=iters, func=func)\n",
    "    p = (100 - percent) / 2\n",
    "    percents = p, 100-p\n",
    "\n",
    "    predict_seq = generate_predictions(result_seq, years, add_resid=True)\n",
    "    low, high = np.percentile(predict_seq, percents, axis=0)\n",
    "    plt.fill_between(years, low, high, alpha=0.2, color='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the high quality category looks like if we take into account uncertainty about how much past data to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes a very long time\n",
    "name = 'high'\n",
    "daily = dailies[name]\n",
    "\n",
    "plt.scatter(daily.years, daily.ppg, alpha=0.1, label=name)\n",
    "plot_intervals(daily, years)\n",
    "plot_predictions(daily, years)\n",
    "plt.xlim([years[0]-0.1, years[-1]+0.1])\n",
    "plt.xlabel('Years');\n",
    "plt.ylabel('Price per gram ($)');\n",
    "plt.title('Predictions');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**   The linear model I used in this chapter has the obvious drawback that it is linear, and there is no reason to expect prices to change linearly over time. We can add flexibility to the model by adding a quadratic term, as we did in Section 11.3.\n",
    "\n",
    "Use a quadratic model to fit the time series of daily prices, and use the model to generate predictions. You will have to write a version of `RunLinearModel` that runs that quadratic model, but after that you should be able to reuse code from the chapter to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "def run_quadratic_model(daily):\n",
    "    \"\"\"Runs a linear model of prices versus years.\n",
    "\n",
    "    daily: DataFrame of daily prices\n",
    "\n",
    "    returns: model, results\n",
    "    \"\"\"\n",
    "    daily['years2'] = daily.years**2\n",
    "    model = smf.ols('ppg ~ years + years2', data=daily)\n",
    "    results = model.fit()\n",
    "    return model, results\n",
    "\n",
    "def fit_quadratic_model(daily):\n",
    "    return smf.ols('ppg ~ years + years2', data=daily).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "name = 'high'\n",
    "daily = dailies[name]\n",
    "\n",
    "model, results = run_quadratic_model(daily)\n",
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fitted_values(model, results, label='High')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.linspace(0, 5, 101)\n",
    "plt.scatter(daily.years, daily.ppg, alpha=0.1, label=name)\n",
    "plot_predictions(daily, years, func=fit_quadratic_model)\n",
    "plt.xlim([years[0]-0.1, years[-1]+0.1])\n",
    "plt.xlabel('Years');\n",
    "plt.ylabel('Price per gram ($)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Write a definition for a class named `SerialCorrelationTest` that extends `HypothesisTest` from Section 9.2. It should take a series and a lag as data, compute the serial correlation of the series with the given lag, and then compute the p-value of the observed correlation.\n",
    "\n",
    "Use this class to test whether the serial correlation in raw price data is statistically significant. Also test the residuals of the linear model and (if you did the previous exercise), the quadratic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SerialCorrelationTest(hypothesis.HypothesisTest):\n",
    "    \n",
    "    def __init__(self, series: pd.Series, lag: int):\n",
    "        self.series = series\n",
    "        self.lag = lag\n",
    "        self.actual = self.test_statistic(self.series)\n",
    "        \n",
    "    def make_model(self):\n",
    "        pass\n",
    "        \n",
    "    def test_statistic(self, data: pd.Series):\n",
    "        \"\"\"Computes the test statistic.\n",
    "\n",
    "        data: tuple of xs and ys\n",
    "        \"\"\"\n",
    "        return abs(serial_corr(data, self.lag))\n",
    "    \n",
    "    def run_model(self):\n",
    "        \"\"\"Run the model of the null hypothesis.\n",
    "\n",
    "        returns: simulated data\n",
    "        \"\"\"\n",
    "        permutation = self.series.reindex(np.random.permutation(self.series.index))\n",
    "        return permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the correlation between consecutive prices\n",
    "\n",
    "name = 'high'\n",
    "daily = dailies[name]\n",
    "\n",
    "test = SerialCorrelationTest(daily.ppg, 1)\n",
    "p_val = test.p_value()\n",
    "print(f'Actual: {test.actual:0.2f}: p-val: {p_val:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for serial correlation in residuals of the linear model\n",
    "\n",
    "results = fit_linear_model(daily)\n",
    "series = results.resid\n",
    "test = SerialCorrelationTest(results.resid, 1)\n",
    "p_val = test.p_value()\n",
    "print(f'Actual: {test.actual:0.2f}: p-val: {p_val:0.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for serial correlation in residuals of the quadratic model\n",
    "results = fit_quadratic_model(daily)\n",
    "test = SerialCorrelationTest(results.resid, 1)\n",
    "p_val = test.p_value()\n",
    "print(f'Actual: {test.actual:0.2f}: p-val: {p_val:0.2f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Worked example:** There are several ways to extend the EWMA model to generate predictions. One of the simplest is something like this:\n",
    "\n",
    "1. Compute the EWMA of the time series and use the last point as an intercept, `inter`.\n",
    "\n",
    "2. Compute the EWMA of differences between successive elements in the time series and use the last point as a slope, `slope`.\n",
    "\n",
    "3. To predict values at future times, compute `inter + slope * dt`, where `dt` is the difference between the time of the prediction and the time of the last observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'high'\n",
    "daily = dailies[name]\n",
    "\n",
    "filled = fill_missing(daily)\n",
    "diffs = filled.ppg.diff()\n",
    "plt.plot(diffs)\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel('Daily change in price per gram ($)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled['slope'] = diffs.ewm(span=365).mean()\n",
    "plt.plot(filled.slope[-365:])\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel('EWMA of diff ($)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the last inter and the mean of the last 30 slopes\n",
    "start = filled.index[-1]\n",
    "inter = filled.ewma[-1]\n",
    "slope = filled.slope[-30:].mean()\n",
    "print(f'start: {start}, intercept: {inter:0.2f}, slope: {slope:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex the DataFrame, adding a year to the end\n",
    "dates = pd.date_range(\n",
    "    filled.index.min(), \n",
    "    filled.index.max() + np.timedelta64(365, 'D')\n",
    ")\n",
    "predicted = filled.reindex(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predicted values and add them to the end\n",
    "predicted['date'] = predicted.index\n",
    "one_day = np.timedelta64(1, 'D')\n",
    "predicted['days'] = (predicted.date - start) / one_day\n",
    "predict = inter + slope * predicted.days\n",
    "predicted.ewma.fillna(predict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the actual values and predictions\n",
    "plt.scatter(daily.ppg, alpha=0.1, label=name)\n",
    "plt.plot(predicted.ewma, color='#ff7f00');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
