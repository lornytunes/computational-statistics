{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Area under the receiver operating curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.integrate import trapezoid\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local\n",
    "import sys\n",
    "sys.path.append('../lib')\n",
    "\n",
    "import compstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# worksheet\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(11, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Configure Jupyter to display the assigned value after an assignment\n",
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Area under ROC\n",
    "\n",
    "As a way of understanding AUC ROC, let's look at the relationship between AUC and Cohen's effect size.\n",
    "\n",
    "Cohen's effect size, `d`, expresses the difference between two groups as the number of standard deviations between the means.\n",
    "\n",
    "As `d` increases, we expect it to be easier to distinguish between groups, so we expect AUC to increase.\n",
    "\n",
    "I'll start in one dimension and then generalize to multiple dimensions.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here are the means and standard deviations for two hypothetical groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mu1 = 0\n",
    "sigma = 1\n",
    "\n",
    "d = 1\n",
    "mu2 = mu1 + d;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I'll generate two random samples with these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "sample1 = np.random.normal(mu1, sigma, n)\n",
    "sample2 = np.random.normal(mu2, sigma, n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we put a threshold at the midpoint between the means, we can compute the fraction of Group 0 that would be above the threshold.\n",
    "\n",
    "I'll call that the false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = (mu1 + mu2) / 2\n",
    "np.mean(sample1 > thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And here's the fraction of Group 1 that would be below the threshold, which I'll call the false negative rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(sample2 < thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plotting misclassification\n",
    "\n",
    "To see what these overlapping distributions look like, I'll plot a kernel density estimate (KDE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def make_kde(sample: np.ndarray) -> pd.Series:\n",
    "    \"\"\"Kernel density estimate.\n",
    "    \n",
    "    sample: sequence\n",
    "    \n",
    "    returns: Series\n",
    "    \"\"\"\n",
    "    xs = np.linspace(-4, 4, 101)\n",
    "    kde = gaussian_kde(sample)\n",
    "    ys = kde.evaluate(xs)\n",
    "    return pd.Series(ys, index=xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_kde(kde: pd.Series, clipped: pd.Series, color: str):\n",
    "    \"\"\"Plot a KDE and fill under the clipped part.\n",
    "    \n",
    "    kde: Series\n",
    "    clipped: Series\n",
    "    color: string\n",
    "    \"\"\"\n",
    "    plt.plot(kde.index, kde, color=color)\n",
    "    plt.fill_between(clipped.index, clipped, color=color, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_misclassification(sample1: np.array, sample2: np.array, thresh: float):\n",
    "    \"\"\"Plot KDEs and shade the areas of misclassification.\n",
    "    \n",
    "    sample1: sequence\n",
    "    sample2: sequence\n",
    "    thresh: number\n",
    "    \"\"\"\n",
    "    kde1 = make_kde(sample1)\n",
    "    # sample1 lower. shade above the threshold (false positives)\n",
    "    clipped = kde1[kde1.index>=thresh]\n",
    "    plot_kde(kde1, clipped, 'C0')\n",
    "\n",
    "    kde2 = make_kde(sample2)\n",
    "    # sample2 higher. shade below the threshold (false negatives)\n",
    "    clipped = kde2[kde2.index<=thresh]\n",
    "    plot_kde(kde2, clipped, 'C1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's what it looks like with the threshold at 0.  There are many false positives, shown in blue, and few false negatives, in orange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_misclassification(sample1, sample2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With a higher threshold, we get fewer false positives, at the cost of more false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_misclassification(sample1, sample2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The receiver operating curve\n",
    "\n",
    "The receiver operating curve (ROC) represents this tradeoff.\n",
    "\n",
    "To plot the ROC, we have to compute the false positive rate (which we saw in the figure above), and the true positive rate (not shown in the figure).\n",
    "\n",
    "The following function computes these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpr_tpr(sample1: np.ndarray, sample2: np.ndarray, thresh: float) -> Tuple[np.float64, np.float64]:\n",
    "    \"\"\"Compute false positive and true positive rates.\n",
    "    \n",
    "    sample1: sequence\n",
    "    sample2: sequence\n",
    "    thresh: number\n",
    "    \n",
    "    returns: tuple of (fpr, tpf)\n",
    "    \"\"\"\n",
    "    # lower sample above the threshold\n",
    "    fpr = np.mean(sample1>thresh)\n",
    "    # true positives - upper sample to the right of the threshold\n",
    "    tpr = np.mean(sample2>thresh)\n",
    "    return fpr, tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When the threshold is high, the false positive rate is low, but so is the true positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tpr(sample1, sample2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As we decrease the threshold, the true positive rate increases, but so does the false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tpr(sample1, sample2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The ROC shows this tradeoff over a range of thresholds.\n",
    "\n",
    "I sweep thresholds from high to low so the ROC goes from left to right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(sample1: np.array, sample2: np.array, label: str):\n",
    "    \"\"\"Plot the ROC curve and return the AUC.\n",
    "    \n",
    "    sample1: sequence\n",
    "    sample2: sequence\n",
    "    label: string\n",
    "    \n",
    "    returns: AUC\n",
    "    \"\"\"\n",
    "    threshes = np.linspace(5, -3)\n",
    "    # a list of (fpr, tpr) tuples\n",
    "    roc = [\n",
    "        fpr_tpr(sample1, sample2, thresh) for thresh in threshes\n",
    "    ]\n",
    "\n",
    "    fpr, tpr = np.transpose(roc)\n",
    "    plt.plot(fpr, tpr, label=label)\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    \n",
    "    auc = trapezoid(tpr, fpr)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's the ROC for the samples.\n",
    "\n",
    "With `d=1`, the area under the curve is about 0.75.  That might be a good number to remember."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = plot_roc(sample1, sample2, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's see what that looks like for a range of `d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1 = 0\n",
    "sigma = 1\n",
    "n = 1000\n",
    "\n",
    "res = []\n",
    "# differences between mu2 and mu1 - i.e the effect size\n",
    "for mu2 in [3, 2, 1.5, 0.75, 0.25]:\n",
    "    sample1 = np.random.normal(mu1, sigma, n)\n",
    "    sample2 = np.random.normal(mu2, sigma, n)\n",
    "    d = (mu2-mu1) / sigma\n",
    "    label = f'd = {d:0.2g}'\n",
    "    auc = plot_roc(sample1, sample2, label)\n",
    "    res.append((d, auc))\n",
    "    \n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(res, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This function computes AUC as a function of `d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc_vs_d(res: np.array, label=None):\n",
    "    d, auc = np.transpose(res)\n",
    "    plt.plot(d, auc, alpha=0.8, label=label)\n",
    "    plt.xlabel('Cohen effect size')\n",
    "    plt.ylabel('Area under ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following figure shows AUC as a function of `d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_auc_vs_d(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not suprisingly, AUC increases as `d` increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multivariate distributions\n",
    "\n",
    "Now let's see what happens if we have more than one variable, with a difference in means along more than one dimension.\n",
    "\n",
    "First, I'll generate a 2-D sample with `d=1` along both dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 1\n",
    "mu1 = [0, 0]\n",
    "mu2 = [d, d]\n",
    "\n",
    "rho = 0\n",
    "sigma = [[1, rho], [rho, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000x2\n",
    "sample1 = multivariate_normal(mu1, sigma).rvs(n)\n",
    "sample2 = multivariate_normal(mu2, sigma).rvs(n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The mean of `sample1` should be near 0 for both features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column means\n",
    "np.mean(sample1, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And the mean of `sample2` should be near 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(sample2, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following scatterplot shows what this looks like in 2-D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(8, 8)\n",
    "# 1000x2 -> 2x1000\n",
    "# the '.' means a scatter plot\n",
    "plt.plot(*sample1.transpose(), '.', alpha=0.3, color='C0')\n",
    "plt.plot(*sample2.transpose(), '.', alpha=0.3, color='C1')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter plot for samples with d=1 in both dimensions');\n",
    "plt.xlim((-3, 4))\n",
    "plt.ylim((-3, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Some points are clearly classifiable, but there is substantial overlap in the distributions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can see the same thing if we estimate a 2-D density function and make a contour plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(-2, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(np.meshgrid(np.linspace(-2, 2), np.linspace(-2, 2))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Based on an example at https://plot.ly/ipython-notebooks/2d-kernel-density-distributions/\n",
    "\n",
    "def kde_scipy(sample: np.ndarray):\n",
    "    \"\"\"Use KDE to compute an array of densities.\n",
    "    \n",
    "    sample: sequence\n",
    "    \n",
    "    returns: tuple of matrixes, (X, Y, Z)\n",
    "    \"\"\"\n",
    "    x = np.linspace(-4, 4)\n",
    "    y = x\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    # ravel converts 100x100 grids into 10000x1 flattened array\n",
    "    positions = np.vstack([Y.ravel(), X.ravel()])\n",
    "\n",
    "    kde = gaussian_kde(sample.T)\n",
    "    kde(positions)\n",
    "    # make z into a 100x100 2d matrix\n",
    "    Z = np.reshape(kde(positions).T, X.shape)\n",
    "\n",
    "    return [X, Y, Z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(8, 8)\n",
    "X, Y, Z = kde_scipy(sample1) \n",
    "plt.contour(X, Y, Z, cmap=plt.cm.Blues, alpha=0.7)\n",
    "\n",
    "X, Y, Z = kde_scipy(sample2) \n",
    "plt.contour(X, Y, Z, cmap=plt.cm.Oranges, alpha=0.7)\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('KDE for samples with d=1 in both dimensions');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification with logistic regression\n",
    "\n",
    "To see how distinguishable the samples are, I'll use logistic regression.\n",
    "\n",
    "To get the data into the right shape, I'll make two DataFrames, label them, concatenate them, and then extract the labels and the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(sample1)\n",
    "# sample 1\n",
    "df1['label'] = 1\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df1[[0,1]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(sample2)\n",
    "# sample 2\n",
    "df2['label'] = 2\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df2[[0,1]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`X` is the array of features; `y` is the vector of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[0, 1]]\n",
    "y = df.label;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we can fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs').fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And compute the AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict_proba(X)[:,1]\n",
    "auc = roc_auc_score(y, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "With two features, we can do better than with just one.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### AUC as a function of rho\n",
    "\n",
    "The following function contains the code from the previous section, with `rho` as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def multivariate_normal_auc(d, rho=0):\n",
    "    \"\"\"Generate multivariate normal samples and classify them.\n",
    "    \n",
    "    d: Cohen's effect size along each dimension\n",
    "    num_dims: number of dimensions\n",
    "    \n",
    "    returns: AUC\n",
    "    \"\"\"\n",
    "    mu1 = [0, 0]\n",
    "    mu2 = [d, d]\n",
    "\n",
    "    sigma = [[1, rho], [rho, 1]]\n",
    "\n",
    "    # generate the samples\n",
    "    sample1 = multivariate_normal(mu1, sigma).rvs(n)\n",
    "    sample2 = multivariate_normal(mu2, sigma).rvs(n)\n",
    "\n",
    "    # label the samples and extract the features and labels\n",
    "    df1 = pd.DataFrame(sample1)\n",
    "    df1['label'] = 1\n",
    "\n",
    "    df2 = pd.DataFrame(sample2)\n",
    "    df2['label'] = 2\n",
    "\n",
    "    df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    X = df.drop(columns='label')\n",
    "    y = df.label\n",
    "    \n",
    "    # run the model\n",
    "    model = LogisticRegression(solver='lbfgs').fit(X, y)\n",
    "    y_pred_prob = model.predict_proba(X)[:,1]\n",
    "\n",
    "    # compute AUC\n",
    "    auc = roc_auc_score(y, y_pred_prob)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can sweep a range of values for `rho`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "figsize(11, 5)\n",
    "res = [(rho, multivariate_normal_auc(d=1, rho=rho))\n",
    "       for rho in np.linspace(-0.9, 0.9)]\n",
    "\n",
    "rhos, aucs = np.transpose(res)\n",
    "plt.plot(rhos, aucs)\n",
    "plt.xlabel('Correlation (rho)')\n",
    "plt.ylabel('Area under ROC')\n",
    "plt.title('AUC as a function of correlation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### AUC as a function of d\n",
    "\n",
    "The following function contains the code from the previous section, generalized to handle more than 2 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_normal_auc(d, num_dims=2):\n",
    "    \"\"\"Generate multivariate normal samples and classify them.\n",
    "    \n",
    "    d: Cohen's effect size along each dimension\n",
    "    num_dims: number of dimensions\n",
    "    \n",
    "    returns: AUC\n",
    "    \"\"\"\n",
    "    # compute the mus\n",
    "    mu1 = np.zeros(num_dims)\n",
    "    mu2 = np.full(num_dims, d)\n",
    "\n",
    "    # and sigma\n",
    "    sigma = np.identity(num_dims)\n",
    "\n",
    "    # generate the samples\n",
    "    sample1 = multivariate_normal(mu1, sigma).rvs(n)\n",
    "    sample2 = multivariate_normal(mu2, sigma).rvs(n)\n",
    "\n",
    "    # label the samples and extract the features and labels\n",
    "    df1 = pd.DataFrame(sample1)\n",
    "    df1['label'] = 1\n",
    "\n",
    "    df2 = pd.DataFrame(sample2)\n",
    "    df2['label'] = 2\n",
    "\n",
    "    df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    X = df.drop(columns='label')\n",
    "    y = df.label\n",
    "    \n",
    "    # run the model\n",
    "    model = LogisticRegression(solver='lbfgs').fit(X, y)\n",
    "    y_pred_prob = model.predict_proba(X)[:,1]\n",
    "\n",
    "    # compute AUC\n",
    "    auc = roc_auc_score(y, y_pred_prob)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Confirming what we have seen before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_normal_auc(d=1, num_dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_normal_auc(d=1, num_dims=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can sweep a range of effect sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc_vs_d(num_dims):\n",
    "    \"\"\"Sweep a range of effect sizes and compute AUC.\n",
    "    \n",
    "    num_dims: number of dimensions\n",
    "    \n",
    "    returns: list of \n",
    "    \"\"\"\n",
    "    effect_sizes = np.linspace(0, 4)\n",
    "\n",
    "    return [(d, multivariate_normal_auc(d, num_dims))\n",
    "            for d in effect_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = compute_auc_vs_d(1)\n",
    "res2 = compute_auc_vs_d(2)\n",
    "res3 = compute_auc_vs_d(3)\n",
    "res4 = compute_auc_vs_d(4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_auc_vs_d(res4, 'num_dim=4')\n",
    "plot_auc_vs_d(res3, 'num_dim=3')\n",
    "plot_auc_vs_d(res2, 'num_dim=2')\n",
    "plot_auc_vs_d(res1, 'num_dim=1')\n",
    "plt.title('AUC vs d for different numbers of features')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With more features, the AUC gets better, assuming the features are independent."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
