{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nsfg\n",
    "import babyboom\n",
    "import population\n",
    "import compstats\n",
    "from cdf import Cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# worksheet\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(11, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some colours\n",
    "LIGHT_BLUE = '#348ABD'\n",
    "PURPLE = '#A60628'\n",
    "DARK_GREEN = '#467821'\n",
    "colours = [LIGHT_BLUE, PURPLE, DARK_GREEN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential distribution\n",
    "\n",
    "Here's what the exponential CDF looks like with a range of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(8, 6)\n",
    "params = (0.5, 1, 2)\n",
    "x = np.linspace(0, 3, 100)\n",
    "for color, p in zip(colours, params):\n",
    "    plt.plot(\n",
    "        x,\n",
    "        stats.expon.cdf(x, scale=1/p),\n",
    "        color=color,\n",
    "        label=f'$\\lambda={p}$'\n",
    "    )\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('CDF')\n",
    "plt.title('Exponential CDF')\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the distribution of interarrival times from a dataset of birth times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = babyboom.read_baby_boom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`diffs` is the difference between consecutive birth times\n",
    "\n",
    "The following plots the cdf distribution of these interarrival times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylabels = (\n",
    "    '$CDF(x)$',\n",
    "    '$1-CDF(x)$',\n",
    ")\n",
    "# axs is a 1x2 array of plot areas\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=2,\n",
    "    figsize=(13, 5,)\n",
    ")\n",
    "sns.ecdfplot(\n",
    "    df.minutes.diff(),\n",
    "    ax = axs[0]\n",
    ")\n",
    "sns.ecdfplot(\n",
    "    df.minutes.diff(),\n",
    "    ax = axs[1],\n",
    "    complementary=True,\n",
    "    # log scale on y axis only\n",
    "    log_scale = (False, True,)\n",
    ");\n",
    "for i, ylabel in enumerate(ylabels):\n",
    "    axs[i].set_xlabel('minutes')\n",
    "    axs[i].set_ylabel(ylabel)\n",
    "axs[1].set_ylim((0.01, 1,))\n",
    "fig.suptitle('CDF of interarrival times (left) and CCDF on a log-y scale (right)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note what the CCDF looks like on a log-y scale.  A straight line is consistent with an exponential distribution.\n",
    "\n",
    "If you plot the complementary CDF (CCDF) of a dataset that you think is exponential, you expect to see a function like:\n",
    "\n",
    "$$\n",
    "y \\approx exp(-\\lambda x)\n",
    "$$\n",
    "\n",
    "Taking the log of both sides yields\n",
    "\n",
    "$$\n",
    "log(y) \\approx -\\lambda x\n",
    "$$\n",
    "\n",
    "So on a log-y scale the CCDF is a straight line with slope $-\\lambda$.\n",
    "\n",
    "It is not exactly straight, which indicates that the exponential distribution is not a perfect model for this data. Most likely the underlying assumption—that a birth is equally likely at any time of day—is not exactly true. Nevertheless, it might be reasonable to model this dataset with an exponential distribution. With that simplification, we can summarize the distribution with a single parameter.\n",
    "\n",
    "The parameter, $\\lambda$, can be interpreted as a rate; that is, the number of events that occur, on average, in a unit of time. In this example, 44 babies are born in 24 hours, so the rate is $\\lambda = 0.0306$ births per minute. The mean of an exponential distribution is $1/\\lambda$, so the mean time between births is 32.7 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nminutes = np.ceil(df.minutes.iloc[-1])\n",
    "nbirths = len(df)\n",
    "print(f'{nbirths} births in {np.ceil(nminutes/60)} hours gives a rate of {nbirths/nminutes:0.3f} births per minute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal distribution\n",
    "\n",
    "Here's what the normal CDF looks like with a range of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = [1, 2, 3]\n",
    "sigmas = [0.5, 0.4, 0.3]\n",
    "x = np.linspace(-1, 4, 100)\n",
    "for mu, sigma in zip(mus, sigmas):\n",
    "    plt.plot(\n",
    "        x,\n",
    "        stats.norm.cdf(x, loc=mu, scale=sigma),\n",
    "        label=f'$\\mathcal{{N}}(\\mu={mu}, \\sigma={sigma})$'\n",
    "    )\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('CDF')\n",
    "plt.title('CDF of normal distributions with a range of parameters')\n",
    "plt.legend(loc='upper left');\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use a normal model to fit the distribution of birth weights from the NSFG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preg = nsfg.read_live_fem_preg()\n",
    "weights = preg.totalwgt_lb.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the observed CDF and the model.  The model fits the data well except in the left tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.trim_mean(weights, proportiontocut=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to trim both the mean and the variance so we use `compstats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, var = compstats.trimmed_mean_var(weights, p=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mean: {mu:0.2f}, Var: {var:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Cdf.from_seq(weights).probs(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.arange(0, 17)\n",
    "df = pd.DataFrame(dict(\n",
    "    weight=x,\n",
    "    data=Cdf.from_seq(weights).probs(x),\n",
    "    model=stats.norm(loc=mu, scale=np.sqrt(var)).cdf(x)\n",
    "))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df.melt(\n",
    "    id_vars = 'weight',\n",
    "    value_vars = ['data', 'model'],\n",
    "    value_name = 'CDF',\n",
    "    var_name = 'Scenario'\n",
    ")\n",
    "df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.lineplot(\n",
    "    data = df_long,\n",
    "    x = 'weight',\n",
    "    y = 'CDF',\n",
    "    hue = 'Scenario'\n",
    ")\n",
    "p.set(\n",
    "    xlabel = 'Birth weight (lbs)',\n",
    "    title = 'Birth weights'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Probability Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sort the values in the sample.\n",
    "2. From a standard normal distribution $\\mathcal{N}(\\mu = 0, \\sigma = 1)$, generate a random sample with the same size as the sample, and sort it.\n",
    "3. Plot the sorted values from the sample versus the random values.\n",
    "\n",
    "A normal probability plot is a visual test for normality.  The following example shows that if the data are actually from a normal distribution, the plot is approximately straight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_qq(ys: np.array) -> Tuple[np.array, np.array]:\n",
    "    \"\"\"Generates data for a normal probability plot.\n",
    "\n",
    "    ys: sequence of values\n",
    "    jitter: float magnitude of jitter added to the ys \n",
    "\n",
    "    returns: numpy arrays xs, ys\n",
    "    \"\"\"\n",
    "    xs = np.random.normal(0, 1, len(ys))\n",
    "    xs.sort()\n",
    "    ys = ys.copy()\n",
    "    ys.sort()\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with a sample that is normal\n",
    "n = 1000\n",
    "sample = stats.norm(loc=0, scale=1).rvs(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = normal_qq(sample)\n",
    "p = sns.lineplot(\n",
    "    x=xs,\n",
    "    y=ys\n",
    ");\n",
    "p.set(\n",
    "    xlabel = 'standard normal sample',\n",
    "    ylabel = 'sample values',\n",
    "    title = 'Normal probability plot',\n",
    "    xlim = (-4, 4)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the normal probability plot for birth weights, showing that the lightest babies are lighter than we expect from the normal mode, and the heaviest babies are heavier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_line(xs: np.array, intercept, slope) -> np.array:\n",
    "    \"\"\"Fits a straight line fit to the given data.\n",
    "\n",
    "    xs: sequence of x (in sorted order)\n",
    "\n",
    "    returns: a numpy array\n",
    "    \"\"\"\n",
    "    return intercept + slope * xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.sqrt(var)\n",
    "xs, ys = normal_qq(weights.values)\n",
    "# are fitted values are a line passing through the mean with a slope of sigma\n",
    "fitted_ys = fit_line(xs, mu, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.lineplot(\n",
    "    x=xs,\n",
    "    y=ys,\n",
    "    label='all live'\n",
    ");\n",
    "p.set(\n",
    "    xlabel = 'standard normal sample',\n",
    "    ylabel = 'Birth weight (lbs)',\n",
    "    title = 'Normal probability plot',\n",
    "    xlim = (-5, 4)\n",
    ");\n",
    "plt.plot(xs, fitted_ys, label='fitted');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we suspect that the deviation in the left tail is due to preterm babies, we can check by selecting only full term births."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_weights = preg.query('prglngth > 36').totalwgt_lb.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the deviation in the left tail is almost gone, but the heaviest babies are still heavy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_xs, term_ys = normal_qq(term_weights.values)\n",
    "xlims = np.array([-4, 4])\n",
    "fitted_ys = fit_line(xlims, mu, std)\n",
    "plt.plot(xs, ys, label = 'all live')\n",
    "plt.plot(term_xs, term_ys, label = 'full term')\n",
    "plt.plot(xlims, fitted_ys, label='fitted', linestyle='dashed');\n",
    "plt.xlabel('standard deviation from the mean')\n",
    "plt.ylabel('Birth weight (lbs)')\n",
    "plt.title('Normal probability plot')\n",
    "plt.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lognormal model\n",
    "\n",
    "If the logarithms of a set of values have a normal distribution, the values have a lognormal distribution. The CDF of the lognormal distribution is the same as the CDF of the normal distribution, with $log \\space x$ substituted for x.\n",
    "\n",
    "$$\n",
    "CDF_{lognormal}(x) = CDF_{normal}(log(x))\n",
    "$$\n",
    "\n",
    "As an example of a lognormal distribution, we'll look at adult weights from the BRFSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('data/brfss.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = df.weight.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.kdeplot(\n",
    "    x = weights,\n",
    "    label = 'Adult weight'\n",
    ")\n",
    "p.set(\n",
    "    xlabel = 'weight (kg)',\n",
    "    ylabel = 'PDF',\n",
    "    title = 'Estimated PDF of adult weight data from the BRFSS'\n",
    ");\n",
    "p.axvline(\n",
    "    weights.mean(),\n",
    "    color='darkred',\n",
    "    linestyle='--',\n",
    "    label = 'Mean',\n",
    "    linewidth=0.8\n",
    ");\n",
    "p.axvline(\n",
    "    np.median(weights),\n",
    "    color='darkgreen',\n",
    "    linestyle='--',\n",
    "    label = 'Median',\n",
    "    linewidth=0.8\n",
    ");\n",
    "p.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution appears skewed to the right. Sure enough, the mean, 79.0, is bigger than the median, 77.3. The sample skewness is 1.1 and Pearson’s median skewness is 0.26.\n",
    "\n",
    "The sign of the skewness coefficient indicates whether the distribution skews left or right, but other than that, they are hard to interpret. Sample skewness is less robust; that is, it is more susceptible to outliers. As a result it is less reliable when applied to skewed distributions, exactly when it would be most relevant.\n",
    "\n",
    "Pearson’s median skewness is based on a computed mean and variance, so it is also susceptible to outliers, but since it does not depend on a third moment, it is somewhat more robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.skew(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compstats.pearson_median_skewness(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function estimates the parameters of a normal distribution and plots the data and a normal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_normal_model(weights: np.array, label: str, title: str):\n",
    "    mean, var = compstats.trimmed_mean_var(weights)\n",
    "    std = np.sqrt(var)\n",
    "    cdf = Cdf.from_seq(weights)\n",
    "    p = sns.lineplot(\n",
    "        x = cdf.xs,\n",
    "        y = cdf.ps,\n",
    "        label = 'data'\n",
    "    );\n",
    "    p.set(\n",
    "        xlabel = label,\n",
    "        ylabel = 'CDF',\n",
    "        title = title\n",
    "    );\n",
    "    plt.plot(\n",
    "        cdf.xs,\n",
    "        stats.norm(loc=mean, scale=std).cdf(cdf.xs),\n",
    "        label = 'model'\n",
    "    )\n",
    "    plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the distribution of adult weights and a normal model, which is not a very good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normal_model(\n",
    "    weights, \n",
    "    label='adult weight (kg)',\n",
    "    title = 'Distribution of adult weights on a linear scale'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the distribution of adult weight and a lognormal model, plotted on a log-x scale.  The model is a better fit for the data, although the heaviest people are heavier than the model expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normal_model(\n",
    "    np.log10(weights), \n",
    "    label='adult weight (log10 kg)',\n",
    "    title = 'Distribution of adult weights on a log scale'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function generates a normal probability plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_qq_plot(values: np.array, label: str, title: str):\n",
    "    \"\"\"Generates a normal probability plot.\n",
    "\n",
    "    weights: sequence\n",
    "    \"\"\"\n",
    "    mu, var = compstats.trimmed_mean_var(values, p=0.01)\n",
    "    std = np.sqrt(var)\n",
    "    xs, ys = normal_qq(values)\n",
    "    xlims = (-5, 5)\n",
    "    fitted_ys = fit_line(np.array(xlims), mu, std)\n",
    "    plt.plot(xs, ys, label = 'data')\n",
    "    plt.plot(xlims, fitted_ys, label='fitted', linestyle='dashed')\n",
    "    plt.xlabel('z')\n",
    "    plt.xlim(xlims)\n",
    "    plt.ylabel(label)\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights[weights <= 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we generate a normal probability plot with adult weights, we can see clearly that the data deviate from the model systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_qq_plot(\n",
    "    weights.values,\n",
    "    'weights (kg)',\n",
    "    'Adult weight (normal plot)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we make a normal probability plot with log weights, the model fit the data well except in the tails, where the heaviest people exceed expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_qq_plot(\n",
    "    np.log10(weights.values),\n",
    "    'weights (log10 kg)',\n",
    "    'Adult weight (log normal plot)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pareto distribution\n",
    "\n",
    "The Pareto distribution is named after the economist Vilfredo Pareto, who used it to describe the distribution of wealth. Since then, it has been used to describe phenomena in the natural and social sciences including sizes of cities and towns, sand particles and meteorites, forest fires and earthquakes. The CDF of the Pareto distribution is:\n",
    "\n",
    "$$\n",
    "CDF(x) = 1 - (\\frac{x}{x_m})^{-\\alpha}\n",
    "$$\n",
    "\n",
    "The parameters xm and α determine the location and shape of the distribution. $x_m$ is the minimum possible value.\n",
    "\n",
    "Here's what the Pareto CDF looks like with a range of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = 0.5\n",
    "xs = np.linspace(0, 10, 100)\n",
    "params = [2, 1, 0.5]\n",
    "for alpha in params:\n",
    "    plt.plot(\n",
    "        xs,\n",
    "        stats.pareto.cdf(xs, scale=xmin, b=alpha),\n",
    "        label=f'a={alpha}'\n",
    "    )\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('CDF')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('CDFs of Pareto distributions with different parameters.')\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you plot the CCDF of a sample from a Pareto distribution on a linear scale, you expect to see a function like:\n",
    "\n",
    "$$\n",
    "y \\approx (\\frac{x}{x_m})^{-\\alpha}\n",
    "$$\n",
    "\n",
    "Taking the log of both sides\n",
    "\n",
    "$$\n",
    "log(y) \\approx -\\alpha(log(x) - log(x_m))\n",
    "$$\n",
    "\n",
    "so if you plot $log(y)$ verses $log(x)$, it should look like a straight line with slope $-\\alpha$ and intercept $\\alpha \\space log(x_m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of populations for cities and towns is sometimes said to be Pareto-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_cdf(xmin, alpha, low, high, n=50):\n",
    "    \"\"\"Generates sequences of xs and ps for a Pareto CDF.\n",
    "\n",
    "    xmin: parameter\n",
    "    alpha: parameter\n",
    "    low: float\n",
    "    high: float\n",
    "    n: number of points to render\n",
    "\n",
    "    returns: numpy arrays (xs, ps)\n",
    "    \"\"\"\n",
    "    if low < xmin:\n",
    "        low = xmin\n",
    "    xs = np.linspace(low, high, n)\n",
    "    ps = stats.pareto.cdf(xs, scale=xmin, b=alpha)\n",
    "    return xs, ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops = population.read_population()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the distribution of population for cities and towns in the U.S., along with a Pareto model.  The model fits the data well in the tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.ecdfplot(\n",
    "    x = pops,\n",
    "    complementary = True,\n",
    "    log_scale = (True, True),\n",
    "    label = 'data'\n",
    ");\n",
    "\n",
    "p.set(\n",
    "    xlabel = 'log10 population',\n",
    "    ylabel = 'CCDF',\n",
    "    title = 'CCDFs of city and town populations, on a log-log scale'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lognormal model might be a better fit for this data (as is often the case for things that are supposed to be Pareto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a normal probability plot for the log-populations.  The model fits the data well except in the right tail, where the biggest cities are bigger than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_qq_plot(\n",
    "    np.log10(pops.values),\n",
    "    'log10 population',\n",
    "    'Number of cities/towns (log10)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random variates\n",
    "\n",
    "When we have an analytic CDF, we can sometimes invert it to generate random values.  The following function generates values from an exponential distribution.\n",
    "\n",
    "$$\n",
    "p = 1 - e^{\\lambda x}\n",
    "$$\n",
    "\n",
    "$$\n",
    "x = \\frac{-log(1-p)}{\\lambda}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def expovariate(lam):\n",
    "    p = random.random()\n",
    "    # inverse of the exponential function\n",
    "    x = -np.log(1-p) / lam\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test it by generating a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [expovariate(lam=2) for _ in range(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plotting the CCDF on a log-y scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.ecdfplot(\n",
    "    x=t,\n",
    "    complementary = True,\n",
    "    # log-y scale\n",
    "    log_scale = (False, True,)\n",
    ");\n",
    "p.set(\n",
    "    xlabel = 'Exponential variate',\n",
    "    ylabel = 'CCDF'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`stats` does this sort of thing much more efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = stats.expon.rvs(size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.ecdfplot(\n",
    "    x=t,\n",
    "    complementary = True,\n",
    "    # log-y scale\n",
    "    log_scale = (False, True,)\n",
    ");\n",
    "p.set(\n",
    "    xlabel = 'Exponential variate',\n",
    "    ylabel = 'CCDF'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A straight line is consistent with an exponential distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an exercise, write a function that generates a Pareto variate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** In the BRFSS (see Section 5.4), the distribution of heights is roughly normal with parameters µ = 178 cm and σ = 7.7 cm for men, and µ = 163 cm and σ = 7.3 cm for women.\n",
    "\n",
    "In order to join Blue Man Group, you have to be male between 5’10” and 6’1” (see http://bluemancasting.com). What percentage of the U.S. male population is in this range? Hint: use `scipy.stats.norm.cdf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy.stats` contains objects that represent analytic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('data/brfss.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['weight'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('sex')['height'].aggregate(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example <tt>scipy.stats.norm</tt> represents a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 178\n",
    "sigma = 7.7\n",
    "dist = stats.norm(loc=mu, scale=sigma)\n",
    "type(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"frozen random variable\" can compute its mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.mean(), dist.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also evaluate its CDF.  How many people are more than one standard deviation below the mean?  About 16%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.cdf(mu-sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many people are between 5'10\" and 6'1\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "low = dist.cdf(177.8)    # 5'10\"\n",
    "high = dist.cdf(185.4)   # 6'1\"\n",
    "print(f'Low: {low:0.2f}, High: {high:0.2f}, In between {high-low:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** To get a feel for the Pareto distribution, let’s see how different the world would be if the distribution of human height were Pareto. With the parameters $x_m = 1m$ and $\\alpha = 1.7$, we get a distribution with a reasonable minimum, 1 m, and median, 1.5 m.\n",
    "\n",
    "Plot this distribution. What is the mean human height in Pareto world? What fraction of the population is shorter than the mean? If there are 7 billion people in Pareto world, how many do we expect to be taller than 1 km? How tall do we expect the tallest person to be?\n",
    "\n",
    "`scipy.stats.pareto` represents a pareto distribution.  In Pareto world, the distribution of human heights has parameters $\\alpha=1.7$ and $x_{min}=1 \\space meter$.  So the shortest person is 100 cm and the median is 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.7\n",
    "# meter\n",
    "xmin = 1  \n",
    "dist = stats.pareto(b=alpha, scale=xmin)\n",
    "dist.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the mean height in Pareto world?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What fraction of people are shorter than the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.cdf(dist.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 7 billion people, how many do we expect to be taller than 1 km?  You could use <tt>dist.cdf</tt> or <tt>dist.sf</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "(1 - dist.cdf(1000)) * 7e9, dist.sf(1000) * 7e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How tall do we expect the tallest person to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way to solve this is to search for a height that we\n",
    "# expect one person out of 7 billion to exceed.\n",
    "\n",
    "# It comes in at roughly 600 kilometers.\n",
    "\n",
    "dist.sf(600000) * 7e9            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way is to use `ppf`, which evaluates the \"percent point function\", which\n",
    "# is the inverse CDF.  So we can compute the height in meters that corresponds to\n",
    "# the probability (1 - 1/7e9).\n",
    "\n",
    "dist.ppf(1 - 1/7e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** The [Weibull](http://wikipedia.org/wiki/Weibull_distribution) distribution is a generalization of the exponential distribution that comes up in failure analysis. Its CDF is\n",
    "\n",
    "$$\n",
    "\\mathrm{CDF}(x) = 1 - \\exp[-(x / \\lambda)^k]\n",
    "$$ \n",
    "\n",
    "Can you find a transformation that makes a Weibull distribution look like a straight line? What do the slope and intercept of the line indicate?\n",
    "\n",
    "Use `random.weibullvariate` to generate a sample from a Weibull distribution and use it to test your transformation.\n",
    "\n",
    "Generate a sample from a Weibull distribution and plot it using a transform that makes a Weibull distribution look like a straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [random.weibullvariate(2, 1) for _ in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = Cdf.from_seq(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_weibull(cdf: Cdf) -> Tuple[np.array, np.array]:\n",
    "    '''\n",
    "    Transforms the CDF of a weibull distribution to look like a straight line\n",
    "    '''\n",
    "    xs = np.delete(cdf.xs, -1)\n",
    "    ps = np.delete(cdf.ps, -1)\n",
    "    ps = -np.log(1-ps)\n",
    "    return xs, ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ps = transform_weibull(cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.lineplot(\n",
    "    x=xs,\n",
    "    y=ps\n",
    ");\n",
    "p.set(\n",
    "    xlabel = 'Weibull variate',\n",
    "    ylabel = 'CCDF'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** For small values of `n`, we don’t expect an empirical distribution to fit an analytic distribution exactly. One way to evaluate the quality of fit is to generate a sample from an analytic distribution and see how well it matches the data.\n",
    "\n",
    "For example, earlier we plotted the distribution of time between births and saw that it is approximately exponential. But the distribution is based on only 44 data points. To see whether the data might have come from an exponential distribution, generate 44 values from an exponential distribution with the same mean as the data, about 33 minutes between births.\n",
    "\n",
    "Plot the distribution of the random values and compare it to the actual distribution. You can use random.expovariate to generate the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = babyboom.read_baby_boom()\n",
    "diffs = df.minutes.diff()\n",
    "ccdf = Cdf.from_seq(diffs).complement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(diffs)\n",
    "lam = 44/24/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array([random.expovariate(lam) for _ in range(n)])\n",
    "model = Cdf.from_seq(sample).complement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only occasionally with 1/lam and the mean of the sample be close\n",
    "print(f'n={n}, lambda={1/lam:0.4f}, Mean={sample.mean():0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    ccdf.xs,\n",
    "    ccdf.ps,\n",
    "    label = 'data'\n",
    ")\n",
    "plt.plot(\n",
    "    model.xs,\n",
    "    model.ps,\n",
    "    label = 'model'\n",
    ");\n",
    "plt.xlabel('Time between births (minutes)')\n",
    "plt.ylabel('CCDF')\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
